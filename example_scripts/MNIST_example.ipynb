{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# cca_zoo: Examples\n",
    "In this notebook I demonstrate the general pipeline I use in the cca_zoo package."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cca_zoo\n",
    "import itertools\n",
    "import os\n",
    "import matplotlib\n",
    "matplotlib.use('TKAgg', force=True)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load MNIST Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data ...\n",
      "loading data ...\n",
      "(1000, 784)\n",
      "(1000, 784)\n"
     ]
    }
   ],
   "source": [
    "os.chdir('..')\n",
    "train_set_1, val_set_1, test_set_1 = cca_zoo.mnist_utils.load_data('noisymnist_view1.gz')\n",
    "train_set_2, val_set_2, test_set_2 = cca_zoo.mnist_utils.load_data('noisymnist_view2.gz')\n",
    "\n",
    "train_set_1 = train_set_1[0][:1000]\n",
    "train_set_2 = train_set_2[0][:1000]\n",
    "val_set_1 = val_set_1[0][:1000]\n",
    "val_set_2 = val_set_2[0][:1000]\n",
    "test_set_1 = test_set_1[0][:1000]\n",
    "test_set_2 = test_set_2[0][:1000]\n",
    "\n",
    "print(train_set_1.shape)\n",
    "print(train_set_2.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Settings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#The number of latent dimensions across models\n",
    "latent_dims = 1\n",
    "#The number of folds used for cross-validation/hyperparameter tuning\n",
    "cv_folds = 5\n",
    "#The number of iterations used for alternating least squares/iterative methods\n",
    "max_als_iter = 200\n",
    "#The number of epochs used for deep learning based models\n",
    "epoch_num = 50"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Linear CCA\n",
    "We can do this via a few different methods\n",
    "- alternating least squares\n",
    "- generalized cca (equivalent to SVD/Eigendecomposition)\n",
    "- multiset cca (equivalent to SVD/Eigendecomposition)\n",
    "- scikit learn (NIPALS)\n",
    "\n",
    "(Note that although the MNIST data here is not full rank,\n",
    "both alternating least squares and NIPALS find least squares solutions\n",
    "and therefore this problem is avoided)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "linear_cca = cca_zoo.linear.Wrapper(latent_dims=latent_dims)\n",
    "\n",
    "linear_cca.fit(train_set_1, train_set_2)\n",
    "\n",
    "linear_cca_results = np.stack((linear_cca.train_correlations[0,1], linear_cca.predict_corr(test_set_1, test_set_2)[0,1]))\n",
    "\n",
    "\n",
    "scikit_cca = cca_zoo.linear.Wrapper(latent_dims=latent_dims, method='scikit')\n",
    "\n",
    "scikit_cca.fit(train_set_1, train_set_2)\n",
    "\n",
    "scikit_cca_results = np.stack((scikit_cca.train_correlations[0,1], scikit_cca.predict_corr(test_set_1, test_set_2)[0,1]))\n",
    "\n",
    "\n",
    "gcca = cca_zoo.linear.Wrapper(latent_dims=latent_dims, method='gcca')\n",
    "\n",
    "#small ammount of regularisation added since data is not full rank\n",
    "params={'c':[1,1]}\n",
    "\n",
    "gcca.fit(train_set_1, train_set_2, params=params)\n",
    "\n",
    "gcca_results = np.stack((scikit_cca.train_correlations[0,1], scikit_cca.predict_corr(test_set_1, test_set_2)[0,1]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Regularized CCA with hyperparameter tuning\n",
    "- penalized matrix decomposition ('pmd')\n",
    "- sparse cca/alternating lasso regression ('scca')\n",
    "- ridge cca/alternating ridge regression ('l2')\n",
    "- parkhomenko sparse cca ('parkhomenko')\n",
    "- elastic ('elastic')\n",
    "\n",
    "parameter candidates for cross validation are given as a list of lists as shown in the examples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation with  pmd\n",
      "number of folds:  5\n",
      "{'c': (1, 1)}\n",
      "0.6425641715357652\n",
      "{'c': (1, 3)}\n",
      "0.6425641715357652\n",
      "{'c': (1, 7)}\n",
      "0.6425641715357652\n",
      "{'c': (1, 9)}\n",
      "0.6425641715357652\n",
      "{'c': (3, 1)}\n",
      "0.6371394001653481\n",
      "{'c': (3, 3)}\n",
      "0.6371394001653481\n",
      "{'c': (3, 7)}\n",
      "0.6371394001653481\n",
      "{'c': (3, 9)}\n",
      "0.6376679112465146\n",
      "{'c': (7, 1)}\n",
      "0.6470317773753032\n",
      "{'c': (7, 3)}\n",
      "0.6470317773753032\n",
      "{'c': (7, 7)}\n",
      "0.6470317773753032\n",
      "{'c': (7, 9)}\n",
      "0.6470317773753032\n",
      "{'c': (9, 1)}\n",
      "0.6441538131918592\n",
      "{'c': (9, 3)}\n",
      "0.6441538131918592\n",
      "{'c': (9, 7)}\n",
      "0.6441538131918592\n",
      "{'c': (9, 9)}\n",
      "0.6441538131918592\n",
      "Best score :  0.6470317773753032\n",
      "{'c': (7, 1)}\n",
      "cross validation with  elastic\n",
      "number of folds:  5\n",
      "{'c': (0.01, 0.01), 'ratio': (0.01, 0.01)}\n",
      "0.07366394435365718\n",
      "{'c': (0.01, 0.01), 'ratio': (0.01, 0.01)}\n",
      "0.07060993526266765\n",
      "{'c': (0.01, 0.01), 'ratio': (0.01, 0.1)}\n",
      "0.03716986524138696\n",
      "{'c': (0.01, 0.01), 'ratio': (0.01, 0.01)}\n",
      "0.0002004684369551958\n",
      "{'c': (0.01, 0.01), 'ratio': (0.01, 0.01)}\n",
      "0.04952230409927184\n",
      "{'c': (0.01, 0.01), 'ratio': (0.01, 0.1)}\n",
      "-0.004259234639938364\n",
      "{'c': (0.01, 0.01), 'ratio': (0.1, 0.01)}\n",
      "0.1935624519041192\n",
      "{'c': (0.01, 0.01), 'ratio': (0.1, 0.01)}\n",
      "0.0464525173455958\n",
      "{'c': (0.01, 0.01), 'ratio': (0.1, 0.1)}\n",
      "0.17365697043721912\n",
      "{'c': (0.01, 0.1), 'ratio': (0.01, 0.01)}\n",
      "0.046863212331046185\n",
      "{'c': (0.01, 0.1), 'ratio': (0.01, 0.01)}\n",
      "0.08386716553732679\n",
      "{'c': (0.01, 0.1), 'ratio': (0.01, 0.1)}\n",
      "-0.01745261784830096\n",
      "{'c': (0.01, 0.1), 'ratio': (0.01, 0.01)}\n",
      "0.13799781756731788\n",
      "{'c': (0.01, 0.1), 'ratio': (0.01, 0.01)}\n",
      "0.052897478109974014\n",
      "{'c': (0.01, 0.1), 'ratio': (0.01, 0.1)}\n",
      "-0.01467511553490607\n",
      "{'c': (0.01, 0.1), 'ratio': (0.1, 0.01)}\n",
      "0.39940280326652366\n",
      "{'c': (0.01, 0.1), 'ratio': (0.1, 0.01)}\n",
      "0.20609920274165133\n",
      "{'c': (0.01, 0.1), 'ratio': (0.1, 0.1)}\n",
      "0.018994391964275943\n",
      "{'c': (0.01, 1), 'ratio': (0.01, 0.01)}\n",
      "0.013672142752739416\n",
      "{'c': (0.01, 1), 'ratio': (0.01, 0.01)}\n",
      "-0.0041723501500194075\n",
      "{'c': (0.01, 1), 'ratio': (0.01, 0.1)}\n",
      "0.3871988763001101\n",
      "{'c': (0.01, 1), 'ratio': (0.01, 0.01)}\n",
      "-0.03570052018571611\n",
      "{'c': (0.01, 1), 'ratio': (0.01, 0.01)}\n",
      "0.024611504694154296\n",
      "{'c': (0.01, 1), 'ratio': (0.01, 0.1)}\n",
      "0.39144070330388536\n",
      "{'c': (0.01, 1), 'ratio': (0.1, 0.01)}\n",
      "-0.0035801933334847825\n",
      "{'c': (0.01, 1), 'ratio': (0.1, 0.01)}\n",
      "0.015455435498761072\n",
      "{'c': (0.01, 1), 'ratio': (0.1, 0.1)}\n",
      "0.3643865295457857\n",
      "{'c': (0.1, 0.01), 'ratio': (0.01, 0.01)}\n",
      "0.21287258388625435\n",
      "{'c': (0.1, 0.01), 'ratio': (0.01, 0.01)}\n",
      "0.15576049579141282\n",
      "{'c': (0.1, 0.01), 'ratio': (0.01, 0.1)}\n",
      "0.260752640491561\n",
      "{'c': (0.1, 0.01), 'ratio': (0.01, 0.01)}\n",
      "0.3136713841950603\n",
      "{'c': (0.1, 0.01), 'ratio': (0.01, 0.01)}\n",
      "0.15745121473899723\n",
      "{'c': (0.1, 0.01), 'ratio': (0.01, 0.1)}\n",
      "0.22403270983550624\n",
      "{'c': (0.1, 0.01), 'ratio': (0.1, 0.01)}\n",
      "0.12683624070516558\n",
      "{'c': (0.1, 0.01), 'ratio': (0.1, 0.01)}\n",
      "0.11124139103965805\n",
      "{'c': (0.1, 0.01), 'ratio': (0.1, 0.1)}\n",
      "0.18827559817383116\n",
      "{'c': (0.1, 0.1), 'ratio': (0.01, 0.01)}\n",
      "0.37101016005872284\n",
      "{'c': (0.1, 0.1), 'ratio': (0.01, 0.01)}\n",
      "0.29215417357380186\n",
      "{'c': (0.1, 0.1), 'ratio': (0.01, 0.1)}\n",
      "0.03776772328912488\n",
      "{'c': (0.1, 0.1), 'ratio': (0.01, 0.01)}\n",
      "0.3403341107015031\n",
      "{'c': (0.1, 0.1), 'ratio': (0.01, 0.01)}\n",
      "0.39322270989473174\n",
      "{'c': (0.1, 0.1), 'ratio': (0.01, 0.1)}\n",
      "-0.0013119494802421277\n",
      "{'c': (0.1, 0.1), 'ratio': (0.1, 0.01)}\n",
      "0.33018614825162534\n",
      "{'c': (0.1, 0.1), 'ratio': (0.1, 0.01)}\n",
      "0.24954744444179658\n",
      "{'c': (0.1, 0.1), 'ratio': (0.1, 0.1)}\n",
      "-0.02526657411688925\n",
      "{'c': (0.1, 1), 'ratio': (0.01, 0.01)}\n",
      "0.028539903273669186\n",
      "{'c': (0.1, 1), 'ratio': (0.01, 0.01)}\n",
      "0.006039317198627376\n",
      "{'c': (0.1, 1), 'ratio': (0.01, 0.1)}\n",
      "0.38321992320711556\n",
      "{'c': (0.1, 1), 'ratio': (0.01, 0.01)}\n",
      "-0.02615283852124318\n",
      "{'c': (0.1, 1), 'ratio': (0.01, 0.01)}\n",
      "0.044618130756864036\n",
      "{'c': (0.1, 1), 'ratio': (0.01, 0.1)}\n",
      "0.37552007308605634\n",
      "{'c': (0.1, 1), 'ratio': (0.1, 0.01)}\n",
      "-0.010699467308684894\n",
      "{'c': (0.1, 1), 'ratio': (0.1, 0.01)}\n",
      "-0.004493176470724075\n",
      "{'c': (0.1, 1), 'ratio': (0.1, 0.1)}\n",
      "-0.005689740457220119\n",
      "{'c': (1, 0.01), 'ratio': (0.01, 0.01)}\n",
      "0.16547775182681007\n",
      "{'c': (1, 0.01), 'ratio': (0.01, 0.01)}\n",
      "0.23119722719754687\n",
      "{'c': (1, 0.01), 'ratio': (0.01, 0.1)}\n",
      "0.28496365486342895\n",
      "{'c': (1, 0.01), 'ratio': (0.01, 0.01)}\n",
      "0.15873923805829734\n",
      "{'c': (1, 0.01), 'ratio': (0.01, 0.01)}\n",
      "0.18589018633711912\n",
      "{'c': (1, 0.01), 'ratio': (0.01, 0.1)}\n",
      "0.2506950835635161\n",
      "{'c': (1, 0.01), 'ratio': (0.1, 0.01)}\n",
      "0.3328383358137851\n",
      "{'c': (1, 0.01), 'ratio': (0.1, 0.01)}\n",
      "0.3328383358137851\n",
      "{'c': (1, 0.01), 'ratio': (0.1, 0.1)}\n",
      "0.4423822588656729\n",
      "{'c': (1, 0.1), 'ratio': (0.01, 0.01)}\n",
      "0.33689268186407895\n",
      "{'c': (1, 0.1), 'ratio': (0.01, 0.01)}\n",
      "0.3406618367133609\n",
      "{'c': (1, 0.1), 'ratio': (0.01, 0.1)}\n",
      "-0.03949319968687119\n",
      "{'c': (1, 0.1), 'ratio': (0.01, 0.01)}\n",
      "0.32533277933058413\n",
      "{'c': (1, 0.1), 'ratio': (0.01, 0.01)}\n",
      "0.34075304960781855\n",
      "{'c': (1, 0.1), 'ratio': (0.01, 0.1)}\n",
      "-0.03437510784276747\n",
      "{'c': (1, 0.1), 'ratio': (0.1, 0.01)}\n",
      "0.47480018510791266\n",
      "{'c': (1, 0.1), 'ratio': (0.1, 0.01)}\n",
      "0.47480018510791266\n",
      "{'c': (1, 0.1), 'ratio': (0.1, 0.1)}\n",
      "-0.020728797607097914\n",
      "{'c': (1, 1), 'ratio': (0.01, 0.01)}\n",
      "-0.029776128850446178\n",
      "{'c': (1, 1), 'ratio': (0.01, 0.01)}\n",
      "-0.06037597550607843\n",
      "{'c': (1, 1), 'ratio': (0.01, 0.1)}\n",
      "0.30274799406043523\n",
      "{'c': (1, 1), 'ratio': (0.01, 0.01)}\n",
      "0.00974295257595255\n",
      "{'c': (1, 1), 'ratio': (0.01, 0.01)}\n",
      "-0.010691118808973244\n",
      "{'c': (1, 1), 'ratio': (0.01, 0.1)}\n",
      "0.20953866400548948\n",
      "{'c': (1, 1), 'ratio': (0.1, 0.01)}\n",
      "-0.020728797607097914\n",
      "{'c': (1, 1), 'ratio': (0.1, 0.01)}\n",
      "-0.020728797607097914\n",
      "{'c': (1, 1), 'ratio': (0.1, 0.1)}\n",
      "0.37200212731989696\n",
      "Best score :  0.47480018510791266\n",
      "{'c': (1, 0.1), 'ratio': (0.1, 0.01)}\n"
     ]
    }
   ],
   "source": [
    "# PMD\n",
    "c1 = [1, 3, 7, 9]\n",
    "c2 = [1, 3, 7, 9]\n",
    "param_candidates = {'c': list(itertools.product(c1, c2))}\n",
    "\n",
    "pmd = cca_zoo.linear.Wrapper(latent_dims=latent_dims, method='pmd',\n",
    "                                 max_iter=max_als_iter).cv_fit(train_set_1, train_set_2,\n",
    "                                                                     param_candidates=param_candidates,\n",
    "                                                                     folds=cv_folds,verbose=True)\n",
    "\n",
    "pmd_results = np.stack((pmd.train_correlations[0, 1, :], pmd.predict_corr(test_set_1, test_set_2)[0, 1, :]))\n",
    "\n",
    "# Elastic\n",
    "c1 = [0.01, 0.1, 1]\n",
    "c2 = [0.01, 0.1, 1]\n",
    "l1_1 = [0.01, 0.01, 0.1]\n",
    "l1_2 = [0.01, 0.01, 0.1]\n",
    "param_candidates = {'c': list(itertools.product(c1, c2)), 'ratio': list(itertools.product(l1_1, l1_2))}\n",
    "\n",
    "elastic = cca_zoo.linear.Wrapper(latent_dims=latent_dims, method='elastic',\n",
    "                                    max_iter=max_als_iter).cv_fit(train_set_1, train_set_2,\n",
    "                                                                     param_candidates=param_candidates,\n",
    "                                                                     folds=cv_folds,verbose=True)\n",
    "\n",
    "elastic_results = np.stack((elastic.train_correlations[0, 1, :], elastic.predict_corr(test_set_1, test_set_2)[0, 1, :]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Kernel CCA\n",
    "\n",
    "Similarly, we can use kernel CCA methods:\n",
    "- regularized kernel CCA ('linear')\n",
    "- sparse cca/alternating lasso regression ('poly')\n",
    "- ridge cca/alternating ridge regression ('gaussian')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation with  kernel\n",
      "number of folds:  5\n",
      "{'kernel': 'linear', 'reg': 10000.0}\n",
      "0.6632553642351521\n",
      "{'kernel': 'linear', 'reg': 100000.0}\n",
      "0.6832730512309577\n",
      "{'kernel': 'linear', 'reg': 1000000.0}\n",
      "0.6503526705119874\n",
      "Best score :  0.6832730512309577\n",
      "{'kernel': 'linear', 'reg': 100000.0}\n",
      "cross validation with  kernel\n",
      "number of folds:  5\n",
      "{'kernel': 'poly', 'degree': 2, 'reg': 1000000.0}\n",
      "0.6055479869308276\n",
      "{'kernel': 'poly', 'degree': 2, 'reg': 10000000.0}\n",
      "0.6055470978669287\n",
      "{'kernel': 'poly', 'degree': 2, 'reg': 100000000.0}\n",
      "0.6055470089572388\n",
      "{'kernel': 'poly', 'degree': 3, 'reg': 1000000.0}\n",
      "0.6068519584932203\n",
      "{'kernel': 'poly', 'degree': 3, 'reg': 10000000.0}\n",
      "0.6068499473122219\n",
      "{'kernel': 'poly', 'degree': 3, 'reg': 100000000.0}\n",
      "0.606849746177138\n",
      "{'kernel': 'poly', 'degree': 4, 'reg': 1000000.0}\n",
      "0.6081621219744734\n",
      "{'kernel': 'poly', 'degree': 4, 'reg': 10000000.0}\n",
      "0.608158526582199\n",
      "{'kernel': 'poly', 'degree': 4, 'reg': 100000000.0}\n",
      "0.608158166988369\n",
      "Best score :  0.6081621219744734\n",
      "{'kernel': 'poly', 'degree': 4, 'reg': 1000000.0}\n",
      "cross validation with  kernel\n",
      "number of folds:  5\n",
      "{'kernel': 'gaussian', 'sigma': 100.0, 'reg': 1000000.0}\n",
      "0.5995259807185055\n",
      "{'kernel': 'gaussian', 'sigma': 100.0, 'reg': 10000000.0}\n",
      "0.59952025742167\n",
      "{'kernel': 'gaussian', 'sigma': 100.0, 'reg': 100000000.0}\n",
      "0.5995196849835914\n",
      "{'kernel': 'gaussian', 'sigma': 1000.0, 'reg': 1000000.0}\n",
      "0.6039950730935677\n",
      "{'kernel': 'gaussian', 'sigma': 1000.0, 'reg': 10000000.0}\n",
      "0.6039949719979114\n",
      "{'kernel': 'gaussian', 'sigma': 1000.0, 'reg': 100000000.0}\n",
      "0.6039949618882978\n",
      "Best score :  0.6039950730935677\n",
      "{'kernel': 'gaussian', 'sigma': 1000.0, 'reg': 1000000.0}\n"
     ]
    }
   ],
   "source": [
    "# r-kernel cca\n",
    "param_candidates = {'kernel': ['linear'], 'reg': [1e+4, 1e+5, 1e+6]}\n",
    "kernel_reg = cca_zoo.linear.Wrapper(latent_dims=latent_dims, method='kernel',\n",
    "                                        max_iter=max_als_iter).cv_fit(train_set_1,train_set_2,\n",
    "                                                                      folds=cv_folds,\n",
    "                                                                      param_candidates=param_candidates,\n",
    "                                                                      verbose=True)\n",
    "kernel_reg_results = np.stack((\n",
    "    kernel_reg.train_correlations[0, 1, :],\n",
    "    kernel_reg.predict_corr(test_set_1, test_set_2)[0, 1, :]))\n",
    "\n",
    "# kernel cca (poly)\n",
    "param_candidates = {'kernel': ['poly'], 'degree': [2, 3, 4], 'reg': [1e+6, 1e+7, 1e+8]}\n",
    "\n",
    "kernel_poly = cca_zoo.linear.Wrapper(latent_dims=latent_dims, method='kernel',\n",
    "                                         max_iter=max_als_iter).cv_fit(train_set_1, train_set_2,\n",
    "                                                                     folds=cv_folds,\n",
    "                                                                     param_candidates=param_candidates,\n",
    "                                                                     verbose=True)\n",
    "\n",
    "kernel_poly_results = np.stack((\n",
    "    kernel_poly.train_correlations[0, 1, :],\n",
    "    kernel_poly.predict_corr(test_set_1, test_set_2)[0, 1, :]))\n",
    "\n",
    "# kernel cca (gaussian)\n",
    "param_candidates = {'kernel': ['gaussian'], 'sigma': [1e+2, 1e+3], 'reg': [1e+6, 1e+7, 1e+8]}\n",
    "\n",
    "kernel_gaussian = cca_zoo.linear.Wrapper(latent_dims=latent_dims, method='kernel',\n",
    "                                             max_iter=max_als_iter).cv_fit(train_set_1, train_set_2,\n",
    "                                                                     folds=cv_folds,\n",
    "                                                                     param_candidates=param_candidates,\n",
    "                                                                     verbose=True)\n",
    "\n",
    "kernel_gaussian_results = np.stack((\n",
    "        kernel_gaussian.train_correlations[0, 1, :],\n",
    "        kernel_gaussian.predict_corr(test_set_1, test_set_2)[0, 1, :]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Deep Learning\n",
    "\n",
    "We also have deep CCA methods (and autoencoder variants)\n",
    "- Deep CCA (DCCA)\n",
    "- Deep Canonically Correlated Autoencoders (DCCAE)\n",
    "- Deep Generalized CCA (DGCCA)\n",
    "\n",
    "Both of the CCA loss and the GCCA loss can be used for DCCA/DCCAE since they are equivalent for two views.\n",
    "\n",
    "To implement DCCA use DCCAE class with lam=0 (default). This multiplies the reconstruction loss term by 0."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model parameters 406050\n",
      "====> Epoch: 0 Average train loss: -0.2710\n",
      "====> Epoch: 0 Average val loss: -0.2761\n",
      "Min loss -3.59\n",
      "====> Epoch: 1 Average train loss: -0.8183\n",
      "====> Epoch: 1 Average val loss: -0.2610\n",
      "====> Epoch: 2 Average train loss: -0.9335\n",
      "====> Epoch: 2 Average val loss: -0.2901\n",
      "Min loss -3.77\n",
      "====> Epoch: 3 Average train loss: -0.9668\n",
      "====> Epoch: 3 Average val loss: -0.3015\n",
      "Min loss -3.92\n",
      "====> Epoch: 4 Average train loss: -0.9739\n",
      "====> Epoch: 4 Average val loss: -0.2962\n",
      "====> Epoch: 5 Average train loss: -0.9692\n",
      "====> Epoch: 5 Average val loss: -0.3169\n",
      "Min loss -4.12\n",
      "====> Epoch: 6 Average train loss: -0.9478\n",
      "====> Epoch: 6 Average val loss: -0.3434\n",
      "Min loss -4.46\n",
      "====> Epoch: 7 Average train loss: -0.9345\n",
      "====> Epoch: 7 Average val loss: -0.3229\n",
      "====> Epoch: 8 Average train loss: -0.9213\n",
      "====> Epoch: 8 Average val loss: -0.3219\n",
      "====> Epoch: 9 Average train loss: -0.9388\n",
      "====> Epoch: 9 Average val loss: -0.3294\n",
      "====> Epoch: 10 Average train loss: -0.9560\n",
      "====> Epoch: 10 Average val loss: -0.3432\n",
      "====> Epoch: 11 Average train loss: -0.9721\n",
      "====> Epoch: 11 Average val loss: -0.3429\n",
      "====> Epoch: 12 Average train loss: -0.9833\n",
      "====> Epoch: 12 Average val loss: -0.3449\n",
      "Min loss -4.48\n",
      "====> Epoch: 13 Average train loss: -0.9860\n",
      "====> Epoch: 13 Average val loss: -0.3489\n",
      "Min loss -4.54\n",
      "====> Epoch: 14 Average train loss: -0.9908\n",
      "====> Epoch: 14 Average val loss: -0.3483\n",
      "====> Epoch: 15 Average train loss: -0.9908\n",
      "====> Epoch: 15 Average val loss: -0.3431\n",
      "====> Epoch: 16 Average train loss: -0.9920\n",
      "====> Epoch: 16 Average val loss: -0.3490\n",
      "Min loss -4.54\n",
      "====> Epoch: 17 Average train loss: -0.9916\n",
      "====> Epoch: 17 Average val loss: -0.3620\n",
      "Min loss -4.71\n",
      "====> Epoch: 18 Average train loss: -0.9922\n",
      "====> Epoch: 18 Average val loss: -0.3517\n",
      "====> Epoch: 19 Average train loss: -0.9900\n",
      "====> Epoch: 19 Average val loss: -0.3392\n",
      "====> Epoch: 20 Average train loss: -0.9909\n",
      "====> Epoch: 20 Average val loss: -0.3515\n",
      "====> Epoch: 21 Average train loss: -0.9876\n",
      "====> Epoch: 21 Average val loss: -0.3777\n",
      "Min loss -4.91\n",
      "====> Epoch: 22 Average train loss: -0.9881\n",
      "====> Epoch: 22 Average val loss: -0.3327\n",
      "====> Epoch: 23 Average train loss: -0.9848\n",
      "====> Epoch: 23 Average val loss: -0.3163\n",
      "====> Epoch: 24 Average train loss: -0.9826\n",
      "====> Epoch: 24 Average val loss: -0.3593\n",
      "====> Epoch: 25 Average train loss: -0.9819\n",
      "====> Epoch: 25 Average val loss: -0.3599\n",
      "====> Epoch: 26 Average train loss: -0.9788\n",
      "====> Epoch: 26 Average val loss: -0.3288\n",
      "====> Epoch: 27 Average train loss: -0.9836\n",
      "====> Epoch: 27 Average val loss: -0.3364\n",
      "====> Epoch: 28 Average train loss: -0.9829\n",
      "====> Epoch: 28 Average val loss: -0.3882\n",
      "Min loss -5.05\n",
      "====> Epoch: 29 Average train loss: -0.9843\n",
      "====> Epoch: 29 Average val loss: -0.3524\n",
      "====> Epoch: 30 Average train loss: -0.9894\n",
      "====> Epoch: 30 Average val loss: -0.3207\n",
      "====> Epoch: 31 Average train loss: -0.9877\n",
      "====> Epoch: 31 Average val loss: -0.3668\n",
      "====> Epoch: 32 Average train loss: -0.9910\n",
      "====> Epoch: 32 Average val loss: -0.3784\n",
      "====> Epoch: 33 Average train loss: -0.9913\n",
      "====> Epoch: 33 Average val loss: -0.3494\n",
      "====> Epoch: 34 Average train loss: -0.9922\n",
      "====> Epoch: 34 Average val loss: -0.3541\n",
      "====> Epoch: 35 Average train loss: -0.9921\n",
      "====> Epoch: 35 Average val loss: -0.3622\n",
      "====> Epoch: 36 Average train loss: -0.9913\n",
      "====> Epoch: 36 Average val loss: -0.3571\n",
      "====> Epoch: 37 Average train loss: -0.9916\n",
      "====> Epoch: 37 Average val loss: -0.3599\n",
      "====> Epoch: 38 Average train loss: -0.9903\n",
      "====> Epoch: 38 Average val loss: -0.3738\n",
      "Early stopping!\n",
      "Number of model parameters 406050\n",
      "====> Epoch: 0 Average train loss: -0.4071\n",
      "====> Epoch: 0 Average val loss: -0.6588\n",
      "Min loss -8.56\n",
      "====> Epoch: 1 Average train loss: -0.8065\n",
      "====> Epoch: 1 Average val loss: -0.6728\n",
      "Min loss -8.75\n",
      "====> Epoch: 2 Average train loss: -0.9302\n",
      "====> Epoch: 2 Average val loss: -0.6601\n",
      "====> Epoch: 3 Average train loss: -0.9750\n",
      "====> Epoch: 3 Average val loss: -0.6600\n",
      "====> Epoch: 4 Average train loss: -0.9910\n",
      "====> Epoch: 4 Average val loss: -0.6640\n",
      "====> Epoch: 5 Average train loss: -0.9945\n",
      "====> Epoch: 5 Average val loss: -0.6672\n",
      "====> Epoch: 6 Average train loss: -0.9932\n",
      "====> Epoch: 6 Average val loss: -0.6631\n",
      "====> Epoch: 7 Average train loss: -0.9864\n",
      "====> Epoch: 7 Average val loss: -0.6602\n",
      "====> Epoch: 8 Average train loss: -0.9708\n",
      "====> Epoch: 8 Average val loss: -0.6469\n",
      "====> Epoch: 9 Average train loss: -0.9327\n",
      "====> Epoch: 9 Average val loss: -0.6104\n",
      "====> Epoch: 10 Average train loss: -0.9132\n",
      "====> Epoch: 10 Average val loss: -0.6176\n",
      "====> Epoch: 11 Average train loss: -0.9235\n",
      "====> Epoch: 11 Average val loss: -0.6915\n",
      "Min loss -8.99\n",
      "====> Epoch: 12 Average train loss: -0.9746\n",
      "====> Epoch: 12 Average val loss: -0.6877\n",
      "====> Epoch: 13 Average train loss: -0.9915\n",
      "====> Epoch: 13 Average val loss: -0.6859\n",
      "====> Epoch: 14 Average train loss: -0.9969\n",
      "====> Epoch: 14 Average val loss: -0.6897\n",
      "====> Epoch: 15 Average train loss: -0.9983\n",
      "====> Epoch: 15 Average val loss: -0.6871\n",
      "====> Epoch: 16 Average train loss: -0.9986\n",
      "====> Epoch: 16 Average val loss: -0.6867\n",
      "====> Epoch: 17 Average train loss: -0.9992\n",
      "====> Epoch: 17 Average val loss: -0.6903\n",
      "====> Epoch: 18 Average train loss: -0.9990\n",
      "====> Epoch: 18 Average val loss: -0.6929\n",
      "Min loss -9.01\n",
      "====> Epoch: 19 Average train loss: -0.9992\n",
      "====> Epoch: 19 Average val loss: -0.6881\n",
      "====> Epoch: 20 Average train loss: -0.9991\n",
      "====> Epoch: 20 Average val loss: -0.6839\n",
      "====> Epoch: 21 Average train loss: -0.9989\n",
      "====> Epoch: 21 Average val loss: -0.6891\n",
      "====> Epoch: 22 Average train loss: -0.9989\n",
      "====> Epoch: 22 Average val loss: -0.6915\n",
      "====> Epoch: 23 Average train loss: -0.9985\n",
      "====> Epoch: 23 Average val loss: -0.6910\n",
      "====> Epoch: 24 Average train loss: -0.9979\n",
      "====> Epoch: 24 Average val loss: -0.6860\n",
      "====> Epoch: 25 Average train loss: -0.9978\n",
      "====> Epoch: 25 Average val loss: -0.6797\n",
      "====> Epoch: 26 Average train loss: -0.9963\n",
      "====> Epoch: 26 Average val loss: -0.6845\n",
      "====> Epoch: 27 Average train loss: -0.9946\n",
      "====> Epoch: 27 Average val loss: -0.6919\n",
      "====> Epoch: 28 Average train loss: -0.9939\n",
      "====> Epoch: 28 Average val loss: -0.6745\n",
      "Early stopping!\n"
     ]
    }
   ],
   "source": [
    "dcca = cca_zoo.deep.Wrapper(latent_dims=latent_dims, epoch_num=epoch_num, method='DCCAE',\n",
    "                                         loss_type='cca')\n",
    "\n",
    "dcca.fit(train_set_1, train_set_2)\n",
    "\n",
    "dcca_results = np.stack((dcca.train_correlations, dcca.predict_corr(test_set_1, test_set_2)))\n",
    "\n",
    "\n",
    "dgcca = cca_zoo.deep.Wrapper(latent_dims=latent_dims, epoch_num=epoch_num, method='DCCAE',\n",
    "                                         loss_type='gcca')\n",
    "\n",
    "dgcca.fit(train_set_1, train_set_2)\n",
    "\n",
    "dgcca_results = np.stack((dcca.train_correlations, dcca.predict_corr(test_set_1, test_set_2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Deep Variational Learning\n",
    "Finally we have Deep Variational CCA methods.\n",
    "- Deep Variational CCA (DVCCA)\n",
    "- Deep Variational CCA - private (DVVCA_p)\n",
    "\n",
    "These are both implemented by the DVCCA class with private=True/False and both_encoders=True/False. If both_encoders,\n",
    "the encoder to the shared information Q(z_shared|x) is modelled for both x_1 and x_2 whereas if both_encoders is false\n",
    "it is modelled for x_1 as in the paper"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model parameters 608808\n",
      "====> Epoch: 0 Average train loss: 3061.8955\n",
      "====> Epoch: 0 Average val loss: 2076.2931\n",
      "====> Epoch: 1 Average train loss: 2102.6470\n",
      "====> Epoch: 1 Average val loss: 2952.6103\n",
      "====> Epoch: 2 Average train loss: 2037.6648\n",
      "====> Epoch: 2 Average val loss: 1909.9441\n",
      "====> Epoch: 3 Average train loss: 2037.5012\n",
      "====> Epoch: 3 Average val loss: 1925.7237\n",
      "====> Epoch: 4 Average train loss: 2026.7704\n",
      "====> Epoch: 4 Average val loss: 2184.4479\n",
      "====> Epoch: 5 Average train loss: 2011.8619\n",
      "====> Epoch: 5 Average val loss: 1892.8650\n",
      "====> Epoch: 6 Average train loss: 1994.3065\n",
      "====> Epoch: 6 Average val loss: 1891.6295\n",
      "====> Epoch: 7 Average train loss: 1985.5509\n",
      "====> Epoch: 7 Average val loss: 1883.3684\n",
      "====> Epoch: 8 Average train loss: 1981.5797\n",
      "====> Epoch: 8 Average val loss: 1880.6190\n",
      "====> Epoch: 9 Average train loss: 1981.6169\n",
      "====> Epoch: 9 Average val loss: 1873.9551\n",
      "Early stopping!\n",
      "Number of model parameters 609320\n",
      "====> Epoch: 0 Average train loss: 3734.4293\n",
      "====> Epoch: 0 Average val loss: 2200.8161\n",
      "====> Epoch: 1 Average train loss: 2388.3788\n",
      "====> Epoch: 1 Average val loss: 2040.5670\n",
      "====> Epoch: 2 Average train loss: 2231.2170\n",
      "====> Epoch: 2 Average val loss: 1989.2187\n",
      "====> Epoch: 3 Average train loss: 2158.7435\n",
      "====> Epoch: 3 Average val loss: 1963.2418\n",
      "====> Epoch: 4 Average train loss: 2118.5760\n",
      "====> Epoch: 4 Average val loss: 1950.9993\n",
      "====> Epoch: 5 Average train loss: 2083.1115\n",
      "====> Epoch: 5 Average val loss: 1936.3434\n",
      "====> Epoch: 6 Average train loss: 2054.9650\n",
      "====> Epoch: 6 Average val loss: 1934.7594\n",
      "====> Epoch: 7 Average train loss: 2038.9436\n",
      "====> Epoch: 7 Average val loss: 1927.8901\n",
      "====> Epoch: 8 Average train loss: 2023.5114\n",
      "====> Epoch: 8 Average val loss: 1913.9634\n",
      "====> Epoch: 9 Average train loss: 2019.5736\n",
      "====> Epoch: 9 Average val loss: 1931.7009\n",
      "Early stopping!\n"
     ]
    }
   ],
   "source": [
    "dvcca = cca_zoo.deep.Wrapper(latent_dims=latent_dims,epoch_num=epoch_num, method='DVCCA',private=False)\n",
    "\n",
    "dvcca.fit(train_set_1, train_set_2)\n",
    "\n",
    "dvcca_results = np.stack((dvcca.train_correlations, dvcca.predict_corr(test_set_1, test_set_2)))\n",
    "\n",
    "\n",
    "dvcca_p = cca_zoo.deep.Wrapper(latent_dims=latent_dims, epoch_num=epoch_num, method='DVCCA',private=True)\n",
    "\n",
    "dvcca_p.fit(train_set_1, train_set_2)\n",
    "\n",
    "dvcca_p_results = np.stack((dvcca_p.train_correlations, dvcca_p.predict_corr(test_set_1, test_set_2)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Make results plot to compare methods"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "all_results = np.stack(\n",
    "    [linear_cca_results,pmd_results,elastic_results,kernel_reg_results,kernel_poly_results,\n",
    "     kernel_gaussian_results,dcca_results,dgcca_results],\n",
    "    axis=0)\n",
    "all_labels = ['linear','pmd','elastic','linear kernel','polynomial kernel',\n",
    "              'gaussian kernel', 'deep CCA', 'deep generalized CCA']\n",
    "\n",
    "cca_zoo.plot_utils.plot_results(all_results, all_labels)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}